{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMs7eEhChioBawGaoBtfxBq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dr-Carlos-Villasenor/Taller_CNN/blob/main/D2_Red_Neuronal_Densa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Red Neuronal Densa (Perceptrón Multicapa MLP)\n",
        "## Dr. Carlos Villaseñor"
      ],
      "metadata": {
        "id": "OA2bDa4ZR5qJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 1. Correr paqueterias"
      ],
      "metadata": {
        "id": "pXflGAH6SC_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ckWvgWOJRp_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 2. Corre el siguiente bloque con diferentes funciones de activación"
      ],
      "metadata": {
        "id": "4K2el12ASGFa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hp-3YtjMROCJ"
      },
      "outputs": [],
      "source": [
        "# Funciones de activación\n",
        "def linear(z, derivative=False):\n",
        "    a = z\n",
        "    if derivative:\n",
        "        da = 1\n",
        "        return a, da\n",
        "    return a\n",
        "\n",
        "\n",
        "def sigmoid(z, derivative=False):\n",
        "    a = 1/(1+np.exp(-z))\n",
        "    if derivative:\n",
        "        da = a * (1 - a)\n",
        "        return a, da\n",
        "    return a\n",
        "\n",
        "\n",
        "def tanh(z, derivative=False):\n",
        "    a = np.tanh(z)\n",
        "    if derivative:\n",
        "        da = (1 - a) * (1 + a)\n",
        "        return a, da\n",
        "    return a\n",
        "\n",
        "\n",
        "def relu(z, derivative=False):\n",
        "    a = z * (z >= 0)\n",
        "    if derivative:\n",
        "        da = np.array(z >= 0, dtype=float)\n",
        "        return a, da\n",
        "    return a"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 3. Completa la siguiente clase para programar la red densa"
      ],
      "metadata": {
        "id": "SsgqxhDxSoJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP:\n",
        "\n",
        "  def __init__(self, layers_dims, \n",
        "               hidden_activation=relu,\n",
        "               output_activation=sigmoid,\n",
        "               learning_rate=0.1):\n",
        "\n",
        "      # Instance Attributes\n",
        "    self.L = len(layers_dims) - 1\n",
        "    self.w = [None] * (self.L + 1)\n",
        "    self.b = [None] * (self.L + 1)\n",
        "    self.f = [None] * (self.L + 1)\n",
        "    self.layers = layers_dims\n",
        "    self.eta = learning_rate\n",
        "\n",
        "    # Initialize weights\n",
        "    for l in range(1, self.L + 1):\n",
        "      self.w[l] = -1 + 2 * np.random.rand(layers_dims[l], layers_dims[l-1])\n",
        "      self.b[l] = -1 + 2 * np.random.rand(layers_dims[l], 1)\n",
        "            \n",
        "      if l == self.L:\n",
        "          self.f[l] = output_activation\n",
        "      else:\n",
        "          self.f[l] = hidden_activation\n",
        "                \n",
        "\n",
        "  def predict(self, X):\n",
        "    a = np.asanyarray(X)\n",
        "    for l in range(1, self.L + 1):\n",
        "        z = np.dot(self.w[l], a) + self.b[l]\n",
        "        a = self.f[l](z)\n",
        "    return a\n",
        "\n",
        "  def fit(self, X, Y, epochs=500):\n",
        "\n",
        "    # Number of samples\n",
        "    p = X.shape[1]\n",
        "\n",
        "    #Gradient Descent\n",
        "    for _ in range(epochs):\n",
        "\n",
        "      # Initialize activations and their derivatives\n",
        "      A = [None] * (self.L + 1)\n",
        "      dA = [None] * (self.L + 1)\n",
        "      lg = [None] * (self.L + 1)\n",
        "                \n",
        "      # Propagation\n",
        "      A[0] = X\n",
        "      for l in range(1, self.L + 1):\n",
        "        Z = np.dot(self.w[l], A[l-1]) + self.b[l]\n",
        "        A[l], dA[l] = self.f[l](Z, derivative=True)\n",
        "\n",
        "      # Backpropagation\n",
        "      for l in range(self.L, 0, -1):\n",
        "        # Calculate local gradient (lg)\n",
        "        if l == self.L:\n",
        "          lg[l] = (Y - A[l]) * dA[l]\n",
        "        else:\n",
        "          lg[l] = np.dot(self.w[l + 1].T, lg[l + 1]) * dA[l]\n",
        "                        \n",
        "      # Update parameters\n",
        "      for l in range(1, self.L + 1):\n",
        "        self.w[l] += (self.eta/p) * np.dot(lg[l], A[l - 1].T)\n",
        "        self.b[l] += (self.eta/p) * np.sum(lg[l])"
      ],
      "metadata": {
        "id": "ElBvQ2NeRuKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 4. Ejecuta la siguiente linea que te ayudará a dibujar las predicciones de la red"
      ],
      "metadata": {
        "id": "ht6fQXUDTVz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MLP_binary_classification_2d(X,Y,net):\n",
        "    plt.figure()\n",
        "    for i in range(X.shape[1]):\n",
        "        if Y[0,i]==0:\n",
        "            plt.plot(X[0,i], X[1,i], '.r')\n",
        "        else:\n",
        "            plt.plot(X[0,i], X[1,i], '.b')\n",
        "    xmin, ymin=np.min(X[0,:])-0.5, np.min(X[1,:])-0.5\n",
        "    xmax, ymax=np.max(X[0,:])+0.5, np.max(X[1,:])+0.5\n",
        "    xx, yy = np.meshgrid(np.linspace(xmin,xmax,100), \n",
        "                         np.linspace(ymin,ymax,100))\n",
        "    data = [xx.ravel(), yy.ravel()]\n",
        "    zz = net.predict(data)\n",
        "    zz = zz.reshape(xx.shape)\n",
        "    plt.contourf(xx,yy,zz, alpha=0.8, \n",
        "                 cmap=plt.cm.RdBu)\n",
        "    plt.xlim([xmin,xmax])\n",
        "    plt.ylim([ymin,ymax])\n",
        "    plt.grid()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "4xhmh7wOTW2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 5. Crea los datos para de la compuerta XOR"
      ],
      "metadata": {
        "id": "QTreo8qLToWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0, 0, 1, 1],\n",
        "              [0, 1, 0, 1]])\n",
        "Y = np.array([[1, 0, 0, 1]]) "
      ],
      "metadata": {
        "id": "cYgaMiwUT1yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 6. Repite el código anterior pero agrega el entrenamiento"
      ],
      "metadata": {
        "id": "06rlKx86UNKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net.fit(X, Y)\n",
        "print(net.predict(X))\n",
        "MLP_binary_classification_2d(X,Y,net)"
      ],
      "metadata": {
        "id": "nXm8x4NVUSxw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}